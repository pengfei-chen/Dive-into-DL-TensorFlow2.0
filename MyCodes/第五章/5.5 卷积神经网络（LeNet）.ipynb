{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imposed-hammer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-pepper",
   "metadata": {},
   "source": [
    "# 5.5 卷积神经网络（LeNet）\n",
    "\n",
    "在 3.9 节（“多层感知机的从零开始实现”）一节里我们构造了一个含单隐藏层的多层感知机模型来对Fashion-MNIST数据集中的图像进行分类。每张图像高和宽均是28像素。我们将图像中的像素逐行展开，得到长度为784的向量，并输入进全连接层中。然而，这种分类方法有一定的局限性。\n",
    "\n",
    "1. 图像在同一列邻近的像素在这个向量中可能相距较远。它们构成的模式可能难以被模型识别。\n",
    "2. 对于大尺寸的输入图像，使用全连接层容易导致模型过大。假设输入是高和宽均为$1,000$像素的彩色照片（含3个通道）。即使全连接层输出个数仍是256，该层权重参数的形状也是$3,000,000\\times 256$：它占用了大约3 GB的内存或显存。这会带来过于复杂的模型和过高的存储开销。\n",
    "\n",
    "卷积层尝试解决这两个问题。一方面，卷积层保留输入形状，使图像的像素在**高和宽**两个方向上的相关性均可能被有效识别；另一方面，卷积层通过滑动窗口将同一卷积核与不同位置的输入重复计算，**从而避免参数尺寸过大**。\n",
    "\n",
    "卷积神经网络就是含卷积层的网络。本节里我们将介绍一个早期用来识别手写数字图像的卷积神经网络：LeNet [1]。这个名字来源于LeNet论文的第一作者Yann LeCun。LeNet展示了通过**梯度下降**训练卷积神经网络可以达到手写数字识别在当时最先进的结果。这个奠基性的工作第一次将卷积神经网络推上舞台，为世人所知。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovely-supervision",
   "metadata": {},
   "source": [
    "## 5.5.1 LeNet模型\n",
    "\n",
    "LeNet分为**卷积层块**和**全连接层块**两个部分。下面我们分别介绍这两个模块。\n",
    "\n",
    "卷积层块里的基本单位是**卷积层后接最大池化层**：**卷积层用来识别图像里的空间模式，如线条和物体局部**，之后的**最大池化层则用来降低卷积层对位置的敏感性**。卷积层块由两个这样的基本单位**重复堆叠**构成。在卷积层块中，每个卷积层都使用$5\\times 5$的窗口，并在输出上使用sigmoid激活函数。第一个卷积层输出通道数为6，第二个卷积层输出通道数则增加到16。**这是因为第二个卷积层比第一个卷积层的输入的高和宽要小，所以增加输出通道使两个卷积层的参数尺寸类似**。卷积层块的两个最大池化层的窗口形状均为$2\\times 2$，且步幅为2。由于池化窗口与步幅形状相同，池化窗口在输入上每次滑动所覆盖的区域互不重叠。\n",
    "\n",
    "卷积层块的输出形状为(批量大小, 通道, 高, 宽)。当卷积层块的输出传入全连接层块时，全连接层块会将小批量中每个样本变平（flatten）。也就是说，**全连接层的输入形状将变成二维**，其中第一维是小批量中的样本，第二维是每个样本变平后的向量表示，且向量长度为通道、高和宽的乘积。全连接层块含3个全连接层。它们的输出个数分别是120、84和10，其中10为输出的类别个数。\n",
    "\n",
    "下面我们通过`Sequential`类来实现LeNet模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "organized-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=6, kernel_size=5,activation='sigmoid',input_shape=(28,28,1)),\n",
    "#     tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='same'),\n",
    "    tf.keras.layers.Conv2D(filters=16,kernel_size=5,activation='sigmoid'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2,strides=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(120,activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(84,activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(10,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-basin",
   "metadata": {},
   "source": [
    "接下来我们构造一个高和宽均为28的单通道数据样本，并逐层进行前向计算来查看每个层的输出形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "beginning-organ",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_14 output shape\t (1, 24, 24, 6)\n",
      "max_pooling2d_12 output shape\t (1, 12, 12, 6)\n",
      "conv2d_15 output shape\t (1, 8, 8, 16)\n",
      "max_pooling2d_13 output shape\t (1, 4, 4, 16)\n",
      "flatten_6 output shape\t (1, 256)\n",
      "dense_18 output shape\t (1, 120)\n",
      "dense_19 output shape\t (1, 84)\n",
      "dense_20 output shape\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "X = tf.random.uniform((1,28,28,1))\n",
    "for layer in net.layers:\n",
    "    X = layer(X)\n",
    "    print(layer.name, 'output shape\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "directed-graduation",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.layers.Conv2D??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "worse-oakland",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.layers.MaxPool2D??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "卷积核的尺寸：5 * 5， 第一层输出  (28 - 5 + 1 ) * (28 - 5 + 1 ) / strides  默认是valid形式 ,又因为卷积核有6个通道，所以输出也有6个通道。  \n",
    "池化层： (24 - 2 + 1) /  strides   默认是valid形式(不用0填充）,向上取整，为 12。如果用0填充的话，会变成 (24 ）/2(步长) = 12  \n",
    "所以这个例子里面，padding 方式对结果没啥影响。\n",
    "下一层卷积： 12 -5 + 1 = 8,  下一层池化： 8 -2 + 1 / 2 向上取整 = 4\n",
    "\n",
    "从通道数6变成 16，参数个数变化  12 * 12 * 6 = 864   ，8 * 8 * 16 = 1024  ，不确定为什么会变成16层。。\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-hanging",
   "metadata": {},
   "source": [
    "可以看到，在卷积层块中输入的高和宽在逐层减小。卷积层由于使用高和宽均为5的卷积核，从而将高和宽分别减小4，而池化层则将高和宽减半，但通道数则从1增加到16。全连接层则逐层减少输出个数，直到变成图像的类别数10。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-missouri",
   "metadata": {},
   "source": [
    "## 5.5.2 获取数据和训练模型\n",
    "\n",
    "下面我们来实验LeNet模型。实验中，我们仍然使用Fashion-MNIST作为训练数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "agricultural-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "medieval-generic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "train_images = tf.reshape(train_images, (train_images.shape[0],train_images.shape[1],train_images.shape[2], 1))\n",
    "print(train_images.shape)\n",
    "\n",
    "test_images = tf.reshape(test_images, (test_images.shape[0],test_images.shape[1],test_images.shape[2], 1))\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-clock",
   "metadata": {},
   "source": [
    "损失函数和训练算法依然采用交叉熵损失函数(cross entropy)和小批量随机梯度下降(SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "potential-missouri",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.9, momentum=0.0, nesterov=False)\n",
    "\n",
    "net.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "closing-bhutan",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 0.4887 - accuracy: 0.8076 - val_loss: 0.4847 - val_accuracy: 0.8078\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 0.4621 - accuracy: 0.8176 - val_loss: 0.4416 - val_accuracy: 0.8227\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 13s 8ms/step - loss: 0.4676 - accuracy: 0.8169 - val_loss: 0.5573 - val_accuracy: 0.7855\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 0.4428 - accuracy: 0.8267 - val_loss: 0.4448 - val_accuracy: 0.8287\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 0.4330 - accuracy: 0.8306 - val_loss: 0.4655 - val_accuracy: 0.8227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1159b712df0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(train_images, train_labels, epochs=5, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "foster-explorer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.4947 - accuracy: 0.8104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4946880340576172, 0.8104000091552734]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.evaluate(test_images, test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-campbell",
   "metadata": {},
   "source": [
    "## 小结\n",
    "\n",
    "* 卷积神经网络就是含卷积层的网络。\n",
    "* LeNet交替使用卷积层和最大池化层后接全连接层来进行图像分类。\n",
    "\n",
    "> 注：本节除了代码之外与原书基本相同，[原书传送门](https://zh.d2l.ai/chapter_convolutional-neural-networks/lenet.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-missile",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
