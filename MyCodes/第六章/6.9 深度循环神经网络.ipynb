{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "egyptian-century",
   "metadata": {},
   "source": [
    "本章到目前为止介绍的循环神经网络只有一个单向的隐藏层，在深度学习应用里，**我们通常会用到含有多个隐藏层的循环神经网络，也称作深度循环神经网络**。图6.11演示了一个**有$L$个隐藏层的深度循环神经网络**，每个隐藏状态不断传递至**当前层的下一时间步**和**当前时间步的下一层**。\n",
    "\n",
    "<div align=center>\n",
    "<img width=\"300\" src=\"../img/chapter06/6.9_deep-rnn.svg\"/>\n",
    "</div>\n",
    "<div align=center>图6.11 深度循环神经网络的架构</div>\n",
    "\n",
    "具体来说，在**时间步$t$里**，设小批量输入$\\boldsymbol{X}_t \\in \\mathbb{R}^{n \\times d}$（样本数为$n$，输入个数为$d$），**第$\\ell$隐藏层**（$\\ell=1,\\ldots,L$）的隐藏状态为$\\boldsymbol{H}_t^{(\\ell)}  \\in \\mathbb{R}^{n \\times h}$（隐藏单元个数为$h$），输出层变量为$\\boldsymbol{O}_t \\in \\mathbb{R}^{n \\times q}$（输出个数为$q$），且隐藏层的激活函数为$\\phi$。第1隐藏层的隐藏状态和之前的计算一样：\n",
    "\n",
    "$$\\boldsymbol{H}_t^{(1)} = \\phi(\\boldsymbol{X}_t \\boldsymbol{W}_{xh}^{(1)} + \\boldsymbol{H}_{t-1}^{(1)} \\boldsymbol{W}_{hh}^{(1)}  + \\boldsymbol{b}_h^{(1)}),$$\n",
    "\n",
    "\n",
    "其中权重$\\boldsymbol{W}_{xh}^{(1)} \\in \\mathbb{R}^{d \\times h}$、$\\boldsymbol{W}_{hh}^{(1)} \\in \\mathbb{R}^{h \\times h}$和偏差 $\\boldsymbol{b}_h^{(1)} \\in \\mathbb{R}^{1 \\times h}$分别为第1隐藏层的模型参数。\n",
    "\n",
    "当$1 < \\ell \\leq L$时，第$\\ell$隐藏层的隐藏状态的表达式为\n",
    "\n",
    "$$\\boldsymbol{H}_t^{(\\ell)} = \\phi(\\boldsymbol{H}_t^{(\\ell-1)} \\boldsymbol{W}_{xh}^{(\\ell)} + \\boldsymbol{H}_{t-1}^{(\\ell)} \\boldsymbol{W}_{hh}^{(\\ell)}  + \\boldsymbol{b}_h^{(\\ell)}),$$\n",
    "\n",
    "**注：向左和向下各走一步。**\n",
    "\n",
    "其中权重$\\boldsymbol{W}_{xh}^{(\\ell)} \\in \\mathbb{R}^{h \\times h}$、$\\boldsymbol{W}_{hh}^{(\\ell)} \\in \\mathbb{R}^{h \\times h}$和偏差 $\\boldsymbol{b}_h^{(\\ell)} \\in \\mathbb{R}^{1 \\times h}$分别为第$\\ell$隐藏层的模型参数。\n",
    "\n",
    "最终，输出层的输出只需基于第$L$隐藏层的隐藏状态：\n",
    "\n",
    "$$\\boldsymbol{O}_t = \\boldsymbol{H}_t^{(L)} \\boldsymbol{W}_{hq} + \\boldsymbol{b}_q,$$\n",
    "\n",
    "其中权重$\\boldsymbol{W}_{hq} \\in \\mathbb{R}^{h \\times q}$和偏差$\\boldsymbol{b}_q \\in \\mathbb{R}^{1 \\times q}$为输出层的模型参数。\n",
    "\n",
    "同多层感知机一样，隐藏层个数$L$和隐藏单元个数$h$都是超参数。此外，如果将隐藏状态的计算换成**门控循环单元**或者**长短期记忆**的计算，我们可以得到**深度门控循环神经网络**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-gender",
   "metadata": {},
   "source": [
    "## 小结\n",
    "\n",
    "* 在深度循环神经网络中，隐藏状态的信息不断传递至当前层的下一时间步和当前时间步的下一层。\n",
    "\n",
    "------------\n",
    "\n",
    "> 注：本节与原书基本相同，[原书传送门](https://zh.d2l.ai/chapter_recurrent-neural-networks/deep-rnn.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-toolbox",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
