{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a225adac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "sys.path.append(\"..\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cac3810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e01beb",
   "metadata": {},
   "source": [
    "## 10.3.1 处理数据集\n",
    "\n",
    "PTB（Penn Tree Bank）是一个常用的小型语料库 [1]。它采样自《华尔街日报》的文章，包括训练集、验证集和测试集。我们将在PTB训练集上训练词嵌入模型。该数据集的每一行作为一个句子。句子中的每个词由空格隔开。\n",
    "\n",
    "确保`ptb.train.txt`已经放在了文件夹`../../data/ptb`下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d14386b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# sentences: 42068'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert 'ptb.train.txt' in os.listdir(\"../../data/ptb\")\n",
    "\n",
    "with open('../../data/ptb/ptb.train.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    # st是sentence的缩写\n",
    "    raw_dataset = [st.split() for st in lines]\n",
    "\n",
    "'# sentences: %d' % len(raw_dataset) # 输出 '# sentences: 42068'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc99f6a0",
   "metadata": {},
   "source": [
    "对于数据集的前3个句子，打印每个句子的词数和前5个词。这个数据集中句尾符为\"&lt;eos&gt;\"，生僻词全用\"&lt;unk&gt;\"表示，数字则被替换成了\"N\"。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11c6921b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# tokens: 24 ['aer', 'banknote', 'berlitz', 'calloway', 'centrust']\n",
      "# tokens: 15 ['pierre', '<unk>', 'N', 'years', 'old']\n",
      "# tokens: 11 ['mr.', '<unk>', 'is', 'chairman', 'of']\n"
     ]
    }
   ],
   "source": [
    "for st in raw_dataset[:3]:\n",
    "    print('# tokens:', len(st), st[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7171417d",
   "metadata": {},
   "source": [
    "### 10.3.1.1 建立词语索引\n",
    "\n",
    "为了计算简单，我们只保留在数据集中至少出现5次的词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7335d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tk是token的缩写\n",
    "counter = collections.Counter([tk for st in raw_dataset for tk in st])\n",
    "counter = dict(filter(lambda x: x[1] >= 5, counter.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8f8422",
   "metadata": {},
   "source": [
    "然后将词映射到整数索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73cc46a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# tokens: 887100'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_token = [tk for tk, _ in counter.items()]\n",
    "token_to_idx = {tk: idx for idx, tk in enumerate(idx_to_token)}\n",
    "dataset = [[token_to_idx[tk] for tk in st if tk in token_to_idx]\n",
    "           for st in raw_dataset]\n",
    "num_tokens = sum([len(st) for st in dataset])\n",
    "'# tokens: %d' % num_tokens # 输出 '# tokens: 887100'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425d3efa",
   "metadata": {},
   "source": [
    "### 10.3.1.2 二次采样\n",
    "\n",
    "文本数据中一般会出现一些高频词，如英文中的“the”“a”和“in”。通常来说，在一个背景窗口中，一个词（如“chip”）和较低频词（如“microprocessor”）同时出现比和较高频词（如“the”）同时出现对训练词嵌入模型更有益。因此，训练词嵌入模型时可以对词进行二次采样 [2]。\n",
    "具体来说，**数据集中每个被索引词$w_i$将有一定概率被丢弃，该丢弃概率为**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21496f1",
   "metadata": {},
   "source": [
    "$$ \n",
    "P(w_i) = \\max\\left(1 - \\sqrt{\\frac{t}{f(w_i)}}, 0\\right),\n",
    "$$ \n",
    "\n",
    "其中 $f(w_i)$ 是数据集中词$w_i$的个数与总词数之比，常数$t$是一个超参数（实验中设为$10^{-4}$）。可见，只有当$f(w_i) > t$时，我们才有可能在二次采样中丢弃词$w_i$，并且越高频的词被丢弃的概率越大。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8eff49e",
   "metadata": {},
   "source": [
    "思想：出现越多越不重要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac1886a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# tokens: 375426'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def discard(idx):\n",
    "    return random.uniform(0, 1) < 1 - math.sqrt(\n",
    "        1e-4 / counter[idx_to_token[idx]] * num_tokens)\n",
    "\n",
    "subsampled_dataset = [[tk for tk in st if not discard(tk)] for st in dataset]\n",
    "'# tokens: %d' % sum([len(st) for st in subsampled_dataset]) # '# tokens: 376200'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45e8d316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3270624157837142"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.uniform(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea15a9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [0, 3, 4, 6, 11, 12], [15, 16, 18, 19, 20]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsampled_dataset[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2678f1",
   "metadata": {},
   "source": [
    "可以看到，二次采样后我们去掉了一半左右的词。下面比较一个词在二次采样前后出现在数据集中的次数。可见高频词“the”的采样率不足1/20。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a62bcdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# the: before=50770, after=2150'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_counts(token):\n",
    "    return '# %s: before=%d, after=%d' % (token, sum(\n",
    "        [st.count(token_to_idx[token]) for st in dataset]), sum(\n",
    "        [st.count(token_to_idx[token]) for st in subsampled_dataset]))\n",
    "\n",
    "compare_counts('the') # '# the: before=50770, after=2013'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc701aa",
   "metadata": {},
   "source": [
    "但低频词“join”则完整地保留了下来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c6e0e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# join: before=45, after=45'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_counts('join') # '# join: before=45, after=45'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3870f50e",
   "metadata": {},
   "source": [
    "### 10.3.1.3 提取中心词和背景词\n",
    "\n",
    "我们将与中心词距离不超过背景窗口大小的词作为它的背景词。下面定义函数提取出所有中心词和它们的背景词。它每次在整数1和`max_window_size`（最大背景窗口）之间随机均匀采样一个整数作为背景窗口大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30d44428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centers_and_contexts(dataset, max_window_size):\n",
    "    centers, contexts = [], []\n",
    "    for st in dataset:\n",
    "        if len(st) < 2:  # 每个句子至少要有2个词才可能组成一对“中心词-背景词”\n",
    "            continue\n",
    "        centers += st\n",
    "        for center_i in range(len(st)):\n",
    "            window_size = random.randint(1, max_window_size)\n",
    "            indices = list(range(max(0, center_i - window_size),\n",
    "                                 min(len(st), center_i + 1 + window_size)))\n",
    "            indices.remove(center_i)  # 将中心词排除在背景词之外\n",
    "            contexts.append([st[idx] for idx in indices])\n",
    "    return centers, contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66c516a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
